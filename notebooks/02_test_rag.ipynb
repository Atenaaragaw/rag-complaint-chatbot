{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d282bb9",
   "metadata": {},
   "source": [
    "1. Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965ff059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful and Environment loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Strategic RAG Imports (Corrected Paths)\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# These two were moved to 'langchain_classic' in the latest update\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "\n",
    "load_dotenv()\n",
    "print(\"‚úÖ Imports successful and Environment loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb2bce5",
   "metadata": {},
   "source": [
    "2. Load the Local Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce7d719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Looking for vector store at: c:\\Users\\Home-User\\rag-complaint-chatbot\\vector_store\\faiss_index_sample\n",
      "‚úÖ Vector store loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 1. Get the directory of the notebook, then go one level UP to the root\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "\n",
    "# 2. Build the correct path to your vector store\n",
    "# This points to: rag-complaint-chatbot/vector_store/faiss_index_sample\n",
    "vector_store_path = os.path.join(project_root, \"vector_store\", \"faiss_index_sample\")\n",
    "\n",
    "print(f\"üìÅ Looking for vector store at: {vector_store_path}\")\n",
    "\n",
    "# 3. Load the store\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "if os.path.exists(vector_store_path):\n",
    "    vector_store = FAISS.load_local(\n",
    "        vector_store_path, \n",
    "        embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(\"‚úÖ Vector store loaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Still not found! Please check if Task 2 actually created the folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654bb47",
   "metadata": {},
   "source": [
    "3. Step-by-Step Retrieval Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b045fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retriever successfully defined and linked to the Vector Store.\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the retriever from the loaded vector store\n",
    "# 'k': 3 tells the engine to find the top 3 most relevant complaint chunks\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(\"‚úÖ Retriever successfully defined and linked to the Vector Store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea3e71",
   "metadata": {},
   "source": [
    "4. LLM Generation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4ef082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä STRATEGIC REPORT:\n",
      "\n",
      "Based on the provided context, here are the top billing issues and their corresponding Complaint IDs:\n",
      "\n",
      "1. **Incorrect Charges:**\n",
      "   - Complaint ID: Not provided in the context. However, it's mentioned that customers have complained about incorrect charges on their social media channels.\n",
      "\n",
      "2. **Disputed Transactions:**\n",
      "   - Complaint ID: Not provided in the context. The customer has mentioned that they have transaction IDs and screenshots of customer support, suggesting they are disputing certain transactions.\n",
      "\n",
      "3. **Banking Issues:**\n",
      "   - Complaint ID: Not provided in the context. The customer has mentioned that they have also faced issues with their bank, suggesting potential banking-related billing issues.\n",
      "\n",
      "4. **Request for Investigation:**\n",
      "   - Complaint ID: Not provided in the context. The customer has explicitly requested an investigation into their account transactions, indicating a serious billing issue.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Mistral model\n",
    "llm = ChatMistralAI(model=\"open-mistral-nemo\", temperature=0.1)\n",
    "\n",
    "# Define the Senior Strategic Analyst prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a Senior Strategic Analyst for CrediTrust. \n",
    "Answer based ONLY on the provided context. Cite the 'Complaint ID' for every fact.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "# Create the chain\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "# Run the test\n",
    "response = rag_chain.invoke({\"input\": \"Summarize the top billing issues and identify the IDs.\"})\n",
    "print(\"üìä STRATEGIC REPORT:\\n\")\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
